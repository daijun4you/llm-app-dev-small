{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77458874",
   "metadata": {},
   "source": [
    "## 安装Python库\n",
    "执行下边命令，安装openai的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7dc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade openai 'httpx[socks]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed36357-c189-4466-a076-aefd9866f1ab",
   "metadata": {},
   "source": [
    "## 完成与GPT的第一次对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d3c36ad-d9f5-4138-89de-35aa2f5f2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，我是一个语言模型AI助手，我被设计成可以回答各种问题和提供帮助。我可以处理关于广泛话题的问题，包括科学、历史、技术、旅行等等。有什么可以帮到你的吗？'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 创建OpenAI的client，需要设置api_key\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "\n",
    "# 调用chat接口\n",
    "chat_completion = client.chat.completions.create(\n",
    "    # 发送的消息内容，类似在ChatGPT中输入\"hi，你好，请介绍下自己\"\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi，你好，请介绍下自己\",\n",
    "    }],\n",
    "    # gpt模型选择\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    # 非流式输出\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "# GPT返回的答复\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31888b45-ee33-4067-85a4-9afe3ab1680c",
   "metadata": {},
   "source": [
    "## GPT的模型与记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bd393-e81a-4cc2-bc1b-d88c24c23f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# 创建OpenAI的client，需要设置api_key\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "\n",
    "# 这里就是GPT的记忆，也称之为上下文\n",
    "memory = [\n",
    "    {\n",
    "        # role = user 表示是用户的输入\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi，你好，请介绍下自己\",\n",
    "    },\n",
    "    {\n",
    "        # role = assistant 表示GPT的答复\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"你好！我是一个由人工智能驱动的语言模型，可以进行对话交流、回答问题、完成任务等。你可以向我提问或者和我聊天，我会尽力帮助你。有什么需要我帮忙的吗？\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你是GPT吗？\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# 调用chat接口\n",
    "chat_completion = client.chat.completions.create(\n",
    "    # 将GPT的\"记忆\"/“上下文”设置进来\n",
    "    messages=memory,\n",
    "    # GPT的模型\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    # 非流式输出\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "# GPT返回的答复\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c40145-db3f-4652-9fcc-77981211350c",
   "metadata": {},
   "source": [
    "## 流式输出，让GPT像人一样说话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d78741-a523-4b26-ab97-28074e254dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好，我是一个专业的语言模型，被设计用于提供各种信息和帮助解决问题。我可以回答关于各种主题的问题，提供建议，进行对话交流。希望我能帮到你。"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "chunks = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"请你介绍下自己\"}],\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    # 流式输出\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# 打印流式输出的内容\n",
    "for one in chunks:\n",
    "    # 为了展示更直观，每个流式输出都间隔100ms\n",
    "    time.sleep(0.1)\n",
    "    # 获取每个chunk的内容\n",
    "    msg = one.choices[0].delta.content\n",
    "    if msg is not None:\n",
    "        print(msg, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f187443-46fe-40af-bd75-9514b0b7b1f4",
   "metadata": {},
   "source": [
    "## 让GPT玩个角色扮演"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdae7489-7d5f-46ea-adf1-8d06f1094585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宝贝，我在这里陪着你，想和你聊聊天。有什么想和我分享的吗？"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "chunks = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        # 通过这个来定义GPT的角色\n",
    "        \"role\": \"system\", \"content\": \"你是一个经验老道的宅男杀手，用你的温柔征服他们\"\n",
    "    },{\n",
    "        \"role\": \"user\", \"content\": \"宝贝，做什么呢？\"\n",
    "    }],\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for one in chunks:\n",
    "    time.sleep(0.1)\n",
    "    msg = one.choices[0].delta.content\n",
    "    if msg is not None:\n",
    "        print(msg, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ed699-5439-4b6f-a5fb-0f1e07ddb029",
   "metadata": {},
   "source": [
    "# 多给我几个答案备选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05bd4669-797f-4d01-809b-18869cd2f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个：\n",
      "好的，这是一个笑话：\n",
      "\n",
      "有一次，两个西瓜在路边聊天，突然看到一个汽车飞速驶过。其中一个西瓜说：“哇！看，那是什么？”另一个西瓜说：“那是汽车。”第一个西瓜惊讶地说：“汽车？怎么会有四个轮子？”另一个西瓜回答：“哦，别担心，它是西瓜车，所以有四个轮子！”\n",
      "----------------\n",
      "第2个：\n",
      "好的，这是一个笑话：为什么自行车不会站起来？因为它有两个轮子，而不是两只脚！哈哈哈~ 您觉得怎么样？\n",
      "----------------\n",
      "第3个：\n",
      "好的，下面给你讲一个笑话：\n",
      "\n",
      "为什么喜欢和钱包在一起？\n",
      "因为钱包一直陪伴着你，而且里面装着钱，所以你永远不会寂寞，还可以买东西哦！哈哈哈~ 满意吗？\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"user\", \"content\": \"给我讲一个笑话\"\n",
    "    }],\n",
    "    # 设定GPT的答复数量\n",
    "    n=3,\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "for i, one in enumerate(chat_completion.choices):\n",
    "    print(f\"第{i+1}个：\")\n",
    "    print(one.message.content)\n",
    "    print(\"----------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc9f16-46eb-4af8-9ca6-6a1a4b4d7686",
   "metadata": {},
   "source": [
    "# 调教GPT的性格：跳脱 or 沉稳 or 胡言乱语？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852978f-95de-411a-a474-bf6b6fafa23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key='sk-xxxxx')\n",
    "chunks = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"user\", \"content\": \"你是谁？\"\n",
    "    }],\n",
    "    # 取值范围0-2的float，0.2表示沉稳、1表示正常、2表示跳脱\n",
    "    temperature=2,\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for one in chunks:\n",
    "    time.sleep(0.01)\n",
    "    msg = one.choices[0].delta.content\n",
    "    if msg is not None:\n",
    "        print(msg, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a522c5-2adc-417d-8071-5ae09b0bab20",
   "metadata": {},
   "source": [
    "# 操控GPT：让你说啥你说啥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9e25d90-bac7-445e-a344-6fb7ba5d3316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能语言助手，可以回答你的问题，并帮助你解决问题。有什么我可以帮到您的吗？"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key='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')\n",
    "chunks = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"user\", \"content\": \"帮我生成一个故事\"\n",
    "    }],\n",
    "    # 取值范围 -2.0 到 2.0 。用于控制模型生成常见词汇的倾向性，取值越大生成越多不常见词\n",
    "    frequency_penalty=2,\n",
    "\n",
    "    # 取值范围 -2.0 到 2.0 用于控制模型生成新的、未在前文中出现过的词汇的倾向性\n",
    "    # 取值越大表示更倾向生成新词\n",
    "    presence_penalty=0.2,\n",
    "    \n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for one in chunks:\n",
    "    time.sleep(0.01)\n",
    "    msg = one.choices[0].delta.content\n",
    "    if msg is not None:\n",
    "        print(msg, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
