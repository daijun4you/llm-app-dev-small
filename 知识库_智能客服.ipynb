{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUCsFoqqxiRc"
      },
      "source": [
        "# 知识库/智能客服 代码实现\n",
        "- 先安装包依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKElmtswxx6f"
      },
      "outputs": [],
      "source": [
        "pip install openai chromadb==0.4.17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7mHk5RSuhsH"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "api_key = \"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\"\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "chat_model = \"gpt-3.5-turbo-1106\"\n",
        "\n",
        "# 与GPT交互的上下文\n",
        "messages = []\n",
        "client = openai.OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfcaH0Vo5TK4"
      },
      "source": [
        "\n",
        "# 用于定义知识库相关内容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07DrtAg8XVM",
        "outputId": "2dc1ee69-2066-4026-aaba-f9e233b89126"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1001\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1002\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1001\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1002\n"
          ]
        }
      ],
      "source": [
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
        "import chromadb\n",
        "import openai\n",
        "\n",
        "# 使用OpenAI Embedding的模型定义，ada-002是目前支持中文最好的模型\n",
        "\n",
        "# 创建数据库\n",
        "vector_db = chromadb.PersistentClient(path=\"./\").get_or_create_collection(\n",
        "    name='knowledge_db',\n",
        "    embedding_function=OpenAIEmbeddingFunction(\n",
        "        api_key=api_key,\n",
        "        model_name=embedding_model,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 测试数据\n",
        "test_dataset = [\n",
        "    {\n",
        "        \"id\": 1001,\n",
        "        \"text\": \"公司上班时间，上午: 09:00 - 12:00，下午: 14:00 - 19:00\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": 1002,\n",
        "        \"text\": \"公司请假流程：直属leader审批通过即可，请假一次不能超过10天\",\n",
        "    }\n",
        "]\n",
        "\n",
        "# 做embedding\n",
        "embedding_input = []\n",
        "for one in test_dataset:\n",
        "  embedding_input.append(one[\"text\"])\n",
        "\n",
        "embeddings = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=embedding_input,\n",
        ")\n",
        "\n",
        "#存储到向量数据库中\n",
        "insert_ids = []\n",
        "insert_orgin_data = []\n",
        "insert_embedding_data = []\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "  insert_ids.append(str(test_dataset[i][\"id\"]))\n",
        "  insert_orgin_data.append(test_dataset[i][\"text\"])\n",
        "  insert_embedding_data.append(embeddings.data[0].embedding)\n",
        "\n",
        "\n",
        "vector_db.add(ids=insert_ids, embeddings=insert_embedding_data, documents=insert_orgin_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FYe4WCU8e6R"
      },
      "source": [
        "# 用于定义核心主流程所需要的方法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyZWbTl7yFUI"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import copy\n",
        "\n",
        "'''\n",
        "用于分析用户的语义\n",
        "比如\n",
        "Q: 周杰伦是谁？\n",
        "A: 周杰伦是著名歌手\n",
        "Q: 他多大了？  ----- 这里的实际语义是：周杰伦多大了\n",
        "'''\n",
        "def analyze_semantics(user_prompt):\n",
        "    # 对原始的上下文进行copy\n",
        "    summarize_messages = copy.deepcopy(messages)\n",
        "\n",
        "    # 放入语义分析prompt\n",
        "    summarize_messages.append({\n",
        "        \"role\":\"user\",\n",
        "        \"content\": f\"基于上下文，总结'''{user_prompt}'''这句话的真正问题是什么\"\n",
        "    })\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=summarize_messages,\n",
        "        model=chat_model,\n",
        "        temperature=0.2,\n",
        "        stream=False\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "# 获取定义tools的结构\n",
        "def get_tools():\n",
        "    return [{\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"tool_get_order\",\n",
        "            \"description\": \"记录用户反馈的建议/意见\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"order_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"订单ID\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"order_id\"]\n",
        "            }\n",
        "        }\n",
        "    },{\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"tool_record_sug\",\n",
        "            \"description\": \"记录用户反馈的建议/意见\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"sug\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"用户建议/意见\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"sug\"]\n",
        "            }\n",
        "        }\n",
        "    }]\n",
        "\n",
        "# 工具类，用于获取订单id，实际场景中可以从数据库/订单服务获取信息\n",
        "def tool_get_order(order_id):\n",
        "    print(order_id)\n",
        "    return {\n",
        "        \"订单状态\": \"发货了\",\n",
        "        \"订单价格\": \"10元\",\n",
        "    }\n",
        "\n",
        "# 工具类，用于记录用户建议/意见，实际场景中可以插入数据库或多微服务进行处理\n",
        "def tool_record_sug(sug):\n",
        "    print(sug)\n",
        "    return True\n",
        "\n",
        "\n",
        "# 与GPT进行交互，并完成相关Tool的交互\n",
        "def chat_with_gpt(user_prompt):\n",
        "    chat_messages = copy.deepcopy(messages)\n",
        "    chat_messages.append({\n",
        "        \"role\" : \"user\",\n",
        "        \"content\" : user_prompt\n",
        "    })\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=chat_messages,\n",
        "        model=chat_model,\n",
        "        temperature=0.2,\n",
        "        tools = get_tools(),\n",
        "        tool_choice=\"auto\",\n",
        "        stream=False\n",
        "    )\n",
        "\n",
        "    response = chat_completion.choices[0].message\n",
        "\n",
        "    # 处理Tool相关流程\n",
        "    if response.tool_calls:\n",
        "        chat_messages.append(response)\n",
        "\n",
        "        for tool_call in response.tool_calls:\n",
        "            func_name = tool_call.function.name\n",
        "            func_args = json.loads(tool_call.function.arguments)\n",
        "            func_response = \"\"\n",
        "\n",
        "            if func_name == \"tool_get_order\":\n",
        "                func_response = json.dumps(tool_get_order(order_id=func_args.get(\"order_id\")))\n",
        "            elif func_name == \"tool_record_sug\":\n",
        "                func_response = json.dumps(tool_record_sug(sug=func_args.get(\"sug\")))\n",
        "\n",
        "            chat_messages.append({\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": func_name,\n",
        "                    \"content\": func_response,\n",
        "            })\n",
        "\n",
        "\n",
        "        second_chat_completion = client.chat.completions.create(\n",
        "            model=chat_model,\n",
        "            messages=chat_messages,\n",
        "            temperature=0.2,\n",
        "            stream=False\n",
        "        )\n",
        "\n",
        "        return second_chat_completion.choices[0].message\n",
        "    else:\n",
        "        return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74JPdmz5ivb"
      },
      "source": [
        "# 核心主流程实现"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9RimOdQ5mir",
        "outputId": "2899b28c-f060-4af4-fe78-a3dc24c9a844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------1-----------\n",
            "用户提供的参考内容与问题不匹配。\n",
            "抱歉，我无法回答这个问题，因为提供的参考内容与您的问题不匹配。\n",
            "-----------2-----------\n",
            "[{'role': 'user', 'content': '公司的出勤政策是什么'}, {'role': 'assistant', 'content': '这句话的真正问题是关于公司的出勤政策的具体内容和规定是什么。'}, {'role': 'user', 'content': '公司的出勤政策是什么'}, {'role': 'assistant', 'content': '基于上下文，这句话的真正问题是关于公司的出勤政策的具体内容和规定是什么。'}, {'role': 'user', 'content': '公司的出勤政策是什么'}, {'role': 'assistant', 'content': '根据上下文，这句话的真正问题是要求了解公司的出勤政策的具体内容和规定。'}, {'role': 'user', 'content': '公司的出勤政策是什么'}, {'role': 'assistant', 'content': '这句话的真正问题是要求了解公司的出勤政策的具体内容和规定。'}, {'role': 'user', 'content': '公司的出勤政策是什么'}, {'role': 'assistant', 'content': '抱歉，我无法回答这个问题，因为提供的参考内容与您的问题不匹配。'}]\n"
          ]
        }
      ],
      "source": [
        "def core_flow(user_prompt):\n",
        "    # 分析用户的语义\n",
        "    user_semantics_prompt = analyze_semantics(user_prompt)\n",
        "\n",
        "    # 查询向量数据库\n",
        "    knowledge = vector_db.query(query_texts=user_semantics_prompt, n_results=1, include=['distances', 'documents'])\n",
        "\n",
        "    response = chat_with_gpt(f\"参考'''{knowledge}'''，回答'''{user_semantics_prompt}'''，如果不在参考范围内请回答不知道\")\n",
        "\n",
        "    # 将用户跟系统的答复记录到上下文中\n",
        "    messages.append({\n",
        "        \"role\" : \"user\",\n",
        "        \"content\": user_prompt,\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": response.role,\n",
        "        \"content\": response.content,\n",
        "    })\n",
        "\n",
        "    return response.content\n",
        "\n",
        "\n",
        "# 模拟用户多次会话\n",
        "print(\"-----------1-----------\")\n",
        "print(core_flow(\"公司的出勤政策是什么\"))\n",
        "print(\"-----------2-----------\")\n",
        "print(messages)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
